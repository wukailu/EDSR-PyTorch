{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path is  ['/home/kailu/EDSR-PyTorch/code', '/home/kailu/EDSR-PyTorch/experiment/other_distill', '/home/kailu/miniconda3/envs/wukailu/lib/python37.zip', '/home/kailu/miniconda3/envs/wukailu/lib/python3.7', '/home/kailu/miniconda3/envs/wukailu/lib/python3.7/lib-dynload', '', '/home/kailu/miniconda3/envs/wukailu/lib/python3.7/site-packages', '/home/kailu/miniconda3/envs/wukailu/lib/python3.7/site-packages/IPython/extensions', '/home/kailu/.ipython']\n",
      "path for model is  /home/kailu/EDSR-PyTorch/code/model/__init__.py\n",
      "current backend is  local_backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"LOCAL_BACKEND\"] = \"1\"\n",
    "os.chdir(\"/home/kailu/EDSR-PyTorch/code\")\n",
    "import sys\n",
    "from frameworks.superresolution.train_sr_model import test_SR_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"/home/kailu/EDSR-PyTorch/code/frameworks/pisr/configs/splainx2/step2.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pdb import set_trace\n",
    "\n",
    "def quantize(img, rgb_range):\n",
    "    pixel_range = 255 / rgb_range\n",
    "    return img.mul(pixel_range).clamp(0, 255).round().div(pixel_range)\n",
    "\n",
    "class PISR_model(nn.Module):\n",
    "    def __init__(self, config_path):\n",
    "        super().__init__()\n",
    "        import frameworks.pisr.utils.config as config\n",
    "        import frameworks.pisr.utils.checkpoint as checkpoint\n",
    "        from frameworks.pisr.models import get_model\n",
    "        from frameworks.pisr.evaluate import get_test_dataloader\n",
    "        config = config.load(config_path)\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"]= str(config.gpu)\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        student_model = get_model(config, 'student').to(device)\n",
    "        optimizer_s = None\n",
    "        checkpoint_s = checkpoint.get_initial_checkpoint(config, model_type='student')\n",
    "        last_epoch_s, step_s = checkpoint.load_checkpoint(student_model, optimizer_s, checkpoint_s, model_type='student')\n",
    "        self.model = student_model\n",
    "        self.config = config\n",
    "        self.old_loader = get_test_dataloader(config)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        student_pred_dict = self.model.forward(LR=x/255)\n",
    "        pred_hr = student_pred_dict['hr']\n",
    "        pred_hr = quantize(pred_hr, self.config.data.rgb_range)\n",
    "#         set_trace()\n",
    "        return pred_hr * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shell(test_model):\n",
    "    from frameworks.superresolution.SRModel import SR_LightModel\n",
    "    shell = SR_LightModel({\n",
    "        'metric': f'psnr_gray_shave_x{test_model.config.data.scale}', \n",
    "        'precision': 32, \n",
    "        'max_lr': 0.0002, \n",
    "        'learning_rate': 0.0002, \n",
    "        'lr': 0.0002,\n",
    "        'weight_decay': 0, \n",
    "        'lr_scheduler': 'OneCycLR', \n",
    "        'optimizer': 'Adam', \n",
    "        'scale': test_model.config.data.scale, \n",
    "        'dataset': {\n",
    "            'workers': 4, \n",
    "            'name': 'DIV2K', \n",
    "            'scale': test_model.config.data.scale,\n",
    "            'total_batch_size': 16, \n",
    "            'patch_size': 192, \n",
    "            'ext': 'sep', \n",
    "            'repeat': 20, \n",
    "            'test_bz': 1, \n",
    "            'batch_size': 16\n",
    "        }, \n",
    "        'rgb_range': 255,\n",
    "        'seed': 233, \n",
    "        'backbone': {\n",
    "            'arch': 'EDSR_layerwise_sr', \n",
    "            'n_feats': 64, \n",
    "            'n_resblocks': 16, \n",
    "            'simple_tail': 1, \n",
    "            'scale': test_model.config.data.scale\n",
    "        }, \n",
    "    })\n",
    "    shell.model = test_model\n",
    "    return shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "data {'scale': 2, 'n_colors': 3, 'rgb_range': 1, 'num_workers': 3, 'pin_memory': False, 'train': [{'name': 'DIV2K', 'params': {'base_dir': '/data/DIV2K', 'augment': True, 'patch_size': 192, 'data_range': '1-800', 'test_every': 1000}}], 'valid': [{'name': 'DIV2K', 'params': {'base_dir': '/data/DIV2K', 'augment': False, 'patch_size': 192, 'data_range': '801-810'}}], 'test': [{'name': 'Set5', 'params': {'base_dir': '/data/Set5'}}, {'name': 'Set14', 'params': {'base_dir': '/data/Set14'}}, {'name': 'B100', 'params': {'base_dir': '/data/B100'}}, {'name': 'Urban100', 'params': {'base_dir': '/data/Urban100'}}]}\n",
      "*************************\n",
      "train {'dir': '../PISR/results/splainnetx2/'}\n",
      "*************************\n",
      "teacher_model {'name': 'plainnet_teacher', 'params': {'scale': 2, 'n_colors': 3, 'm': 4, 'k': 1, 'encoder': 'lcscc', 'n_feats': 64, 'num_modules': 19}}\n",
      "*************************\n",
      "params {'scale': 2, 'n_colors': 3, 'm': 4, 'k': 1, 'encoder': 'lcscc', 'n_feats': 64, 'num_modules': 19}\n",
      "*************************\n",
      "student_model {'name': 'plainnet_student', 'params': {'scale': 2, 'n_colors': 3, 'n_feats': 64, 'num_modules': 19, 'initialize_from': ['../PISR/results/splainnetx2/plainnet_teacher/checkpoint/'], 'modules_to_initialize': [['feature_extraction', 'last_layer']], 'vid_info': ['feature_extraction:None']}}\n",
      "*************************\n",
      "params {'scale': 2, 'n_colors': 3, 'n_feats': 64, 'num_modules': 19, 'initialize_from': ['../PISR/results/splainnetx2/plainnet_teacher/checkpoint/'], 'modules_to_initialize': [['feature_extraction', 'last_layer']], 'vid_info': ['feature_extraction:None']}\n",
      "*************************\n",
      "train {'batch_size': 16, 'num_epochs': 1000, 'teacher_dir': '', 'student_dir': ''}\n",
      "*************************\n",
      "eval {'batch_size': 1}\n",
      "*************************\n",
      "scheduler {'name': 'cosine', 'params': {'T_max': 1000, 'eta_min': 1e-05}}\n",
      "*************************\n",
      "params {'T_max': 1000, 'eta_min': 1e-05}\n",
      "*************************\n",
      "optimizer {'name': 'adam', 'params': {'lr': 0.001}}\n",
      "*************************\n",
      "params {'lr': 0.001}\n",
      "*************************\n",
      "loss {'name': 'vid_loss', 'params': {'reduction': 'mean', 'lambda1': 1, 'lambda2': 1e-06, 'pdf': 'laplace'}}\n",
      "*************************\n",
      "params {'reduction': 'mean', 'lambda1': 1, 'lambda2': 1e-06, 'pdf': 'laplace'}\n",
      "*************************\n",
      "visualizer {'name': 'step2'}\n",
      "get_plainnet_student\n",
      "feature_extraction is initialized using  kaiming_normal\n",
      "last_layer is initialized using  kaiming_normal\n",
      "../PISR/results/splainnetx2/plainnet_teacher/checkpoint/\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "pretrain parameters: feature_extraction\n",
      "load checkpoint from ../PISR/results/splainnetx2/plainnet_student/checkpoint/epoch_0896.pth\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "dataset_params: {'batch_size': 16, 'total_batch_size': 16, 'workers': 4, 'name': 'DIV2K', 'scale': 2, 'patch_size': 192, 'ext': 'sep', 'repeat': 20, 'test_bz': 1, 'dataset_mapping': (0, 1, 2), 'dataset_transforms': (0, 1, 1)}\n",
      "Preprocessing high resolution sr data...\n",
      "Preprocessing low resolution sr data...\n",
      "Preprocessing high resolution sr data...\n",
      "Preprocessing low resolution sr data...\n",
      "len(dataset): 16000\n",
      "len(dataset): 10\n",
      "len(dataset): 10\n"
     ]
    }
   ],
   "source": [
    "model = create_shell(PISR_model(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_params: {'name': 'Set5', 'test_only': True, 'patch_size': 192, 'ext': 'sep', 'scale': 2, 'batch_size': 1, 'dataset_mapping': (0, 1, 2), 'dataset_transforms': (0, 1, 1)}\n",
      "len(dataset): 5\n",
      "len(dataset): 5\n",
      "len(dataset): 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ea91116f49489db4e299091cb592a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/psnr_gray_shave_x2': 37.32267379760742}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------> Set5_psnr_gray_shave_x2 = 37.32267379760742 <-------------\n",
      "dataset_params: {'name': 'Set14', 'test_only': True, 'patch_size': 192, 'ext': 'sep', 'scale': 2, 'batch_size': 1, 'dataset_mapping': (0, 1, 2), 'dataset_transforms': (0, 1, 1)}\n",
      "len(dataset): 14\n",
      "len(dataset): 14\n",
      "len(dataset): 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7385640c65694918bfb2bfa81a2dd9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/psnr_gray_shave_x2': 32.9564323425293}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------> Set14_psnr_gray_shave_x2 = 32.9564323425293 <-------------\n",
      "dataset_params: {'name': 'B100', 'test_only': True, 'patch_size': 192, 'ext': 'sep', 'scale': 2, 'batch_size': 1, 'dataset_mapping': (0, 1, 2), 'dataset_transforms': (0, 1, 1)}\n",
      "len(dataset): 100\n",
      "len(dataset): 100\n",
      "len(dataset): 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0e2d4bfa3c44d5a1234f0719fc1e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/psnr_gray_shave_x2': 31.70647621154785}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------> B100_psnr_gray_shave_x2 = 31.70647621154785 <-------------\n",
      "dataset_params: {'name': 'Urban100', 'test_only': True, 'patch_size': 192, 'ext': 'sep', 'scale': 2, 'batch_size': 1, 'dataset_mapping': (0, 1, 2), 'dataset_transforms': (0, 1, 1)}\n",
      "len(dataset): 100\n",
      "len(dataset): 100\n",
      "len(dataset): 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8153228803e249a5bc243d3cde89e755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test/psnr_gray_shave_x2': 30.481748580932617}\n",
      "--------------------------------------------------------------------------------\n",
      "--------------> Urban100_psnr_gray_shave_x2 = 30.481748580932617 <-------------\n"
     ]
    }
   ],
   "source": [
    "test_SR_benchmark(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wukailu] *",
   "language": "python",
   "name": "conda-env-wukailu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
